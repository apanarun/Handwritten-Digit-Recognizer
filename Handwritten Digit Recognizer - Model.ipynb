{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Importing the Necessary Modules"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras import backend as K\n\n# the data, split between train and test sets\n(x_train,y_train),(x_test,y_test) = mnist.load_data()\n\nprint(x_train.shape,y_train.shape)","execution_count":2,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"},{"output_type":"stream","text":"Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n11493376/11490434 [==============================] - 0s 0us/step\n(60000, 28, 28) (60000,)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# 2. Preprocess the Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = x_train.reshape(x_train.shape[0],28,28,1)\nx_test = x_test.reshape(x_test.shape[0],28,28,1)\ninput_shape = (28, 28, 1)\n\n# convert class vectors to binary class matrices\nnum_classes = 10\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)\n\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train /= 255\nx_test /= 255\n\nprint(x_train.shape)\nx_test.shape\n","execution_count":3,"outputs":[{"output_type":"stream","text":"(60000, 28, 28, 1)\n","name":"stdout"},{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"(10000, 28, 28, 1)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# 3. Create the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 16 * tpu_strategy.num_replicas_in_sync\nepochs=10\n\nimport tensorflow as tf\n# detect and init the TPU\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver()\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)\n\n# instantiate a distribution strategy\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\n# instantiating the model in the strategy scope creates the model on the TPU\nwith tpu_strategy.scope():\n    model = Sequential() \n    model.add(Conv2D(32, kernel_size=(3,3), activation='relu',input_shape=input_shape))\n    model.add(Conv2D(64,(3,3),activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(Dropout(0.25))\n    model.add(Flatten())\n    model.add(Dense(256, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(num_classes, activation='softmax'))\n    \n    model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(),metrics=['accuracy'])\n","execution_count":13,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Train the Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# train model normally\nhist = model.fit(x_train, \n                 y_train, \n                 batch_size=batch_size, \n                 epochs=1, \n                 verbose = 1,\n                 validation_data=(x_test, y_test))\n\n\nmodel.save('Handwritten-digit-mnist.h5')","execution_count":32,"outputs":[{"output_type":"stream","text":"469/469 [==============================] - 6s 12ms/step - loss: 0.3932 - accuracy: 0.8804 - val_loss: 0.2751 - val_accuracy: 0.9216\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# 5. Evaluate the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"score = model.evaluate(x_test,y_test,verbose=0)\nscore","execution_count":33,"outputs":[{"output_type":"execute_result","execution_count":33,"data":{"text/plain":"[0.2750552296638489, 0.9215999841690063]"},"metadata":{}}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}